{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import ResNet50_Weights\n",
    "import numpy as np\n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "path_clean = \"E:\\\\watermarking\\\\brain_tumor_mri_dataset\"\n",
    "path_watermarked = \"E:\\\\watermarking\\\\watermarked_brain_tumor_mri_dataset\"\n",
    "# Data preprocessing and augmentation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets and dataloaders\n",
    "clean_dataset = datasets.ImageFolder(root=path_clean, transform=data_transforms)\n",
    "watermarked_dataset = datasets.ImageFolder(root=path_watermarked, transform=data_transforms)\n",
    "\n",
    "clean_loader = DataLoader(clean_dataset, batch_size=32, shuffle=False)\n",
    "watermarked_loader = DataLoader(watermarked_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet50 model\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) \n",
    "model.load_state_dict(torch.load('mri_model.pth', map_location=device, weights_only=True))\n",
    "model.to(device)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Results storage\n",
    "results = {\n",
    "    \"clean\": [],\n",
    "    \"watermarked\": []\n",
    "}\n",
    "\n",
    "# Set epoch num for testing\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Initialize metrics for both datasets\n",
    "    for dataset_name in ['clean', 'watermarked']:\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        truth_labels = []\n",
    "        predicted_labels = []\n",
    "        confidence_scores = []\n",
    "\n",
    "        # Select the appropriate DataLoader\n",
    "        data_loader = clean_loader if dataset_name == 'clean' else watermarked_loader\n",
    "\n",
    "        # Validation/testing loop\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)  \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Apply softmax to get confidence scores\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                confidence = torch.max(probabilities, dim=1)[0]  # Get max confidence per sample\n",
    "                \n",
    "                # Get predicted labels\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Update metrics\n",
    "                epoch_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                truth_labels.extend(labels.cpu().numpy())\n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                confidence_scores.extend(confidence.cpu().numpy())\n",
    "\n",
    "        # Calculate epoch results\n",
    "        avg_loss = epoch_loss / len(data_loader)\n",
    "        accuracy = correct / total\n",
    "        avg_confidence = np.mean(confidence_scores)\n",
    "\n",
    "        # Save results for the current dataset\n",
    "        results[dataset_name].append({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": avg_loss,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"avg_confidence\": avg_confidence\n",
    "        })\n",
    "\n",
    "# Print results for both datasets\n",
    "print(\"\\nFinal Testing Results Over 10 Epochs:\\n\")\n",
    "for dataset_name in results:\n",
    "    print(f\"Results for {dataset_name.capitalize()} Dataset:\")\n",
    "    for res in results[dataset_name]:\n",
    "        print(f\"  Epoch {res['epoch']} - Loss: {res['loss']:.4f}, Accuracy: {res['accuracy']:.2%}, Avg Confidence: {res['avg_confidence']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
